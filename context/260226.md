# Quincunx 项目交接文件

**项目代号**: Quincunx (⁙)
**日期**: 2026年2月26日
**上下文**: 用户正在设计一个基于 Orchid 工作流引擎的声乐合成编排核心，灵感来源于 OpenUTAU 的编辑器架构。本文件记录了所有讨论过的设计决策、未解决问题和用户背景，供后续对话无缝衔接。
**模型**: Gemini 3 Pro + Claude Opus 4.6 + Gemini 3.1 Pro

---

## 1. 用户画像

### 技术背景

- **主力语言/生态**: Elixir / BEAM，对 OTP 概念（GenServer、ETS、Supervisor）熟悉
- **Orchid 作者**: 用户是 Orchid 库（`hex.pm/packages/orchid`，当前 v0.5.5）的开发者，对其内部架构有完全掌控力
- **相关项目**: 
  - [Qy-Editor](https://ges233.github.io/2025/03/Qy-Editor-demo/) — 个人早期项目（中文），Orchid 的灵感来源
  - [OrchidDehydration](https://github.com/SynapticStrings/OrchidDehydration) — 基于 Orchid 的博客渲染引擎重构被用到的大容量数据缓存，其中包含 Cache Hook 部分特征的原型实现
  - OrchidSymbiont — 让 Orchid 能调用重型服务（Ortex/NxServing、ErlPort、NIF、HTTP）的伴生库
- **领域知识**: 对声乐合成流水线（pitch extraction、mel spectrogram、vocoder、mixing）有概念性了解；对 OpenUTAU 的用户体验和编辑模型比较熟悉
- **交流偏好**: 中英文混用，技术讨论倾向英文术语但复杂思考切回中文；容易被过多细节 overwhelm，偏好先讨论架构/Scope 再落地代码

### 动机

用户希望构建一个**不包含模型与领域代码本身**的编排核心层，实现：

1. 基于乐句的**增量渲染**体验
2. 通过**参数曲线（Bézier 等）**对合成参数进行精细调制
3. 后端无关（Python ONNX 推理、HTTP 服务、本地 NIF 均可插拔）
4. 可嵌入更大系统（编辑器、实时引擎）

---

## 2. Quincunx 的定位与边界

### 是什么

| 属性 | 描述 |
|------|------|
| 编排核心 | 管理"从用户编辑到音频输出"的全流水线调度 |
| 增量引擎 | 基于脏区追踪，只重算受影响的乐句/阶段 |
| 参数曲线系统 | 提供 Cubic Bézier、线性插值等曲线原语 |
| 后端无关 | 通过 Orchid Step 抽象封装推理后端 |
| BEAM 嵌入式 | 设计为 library，不自带 GUI ，可能有 supervision tree |

### 不是什么

- ❌ 歌声合成编辑器（无 GUI）
- ❌ DAW
- ❌ 声学模型实现
- ❌ 训练工具链

---

## 3. 核心架构讨论

### 3.1 增量生成的粒度 — 乐句级

**关键结论**: 增量粒度定在**乐句 (Phrase)** 级别，而非音节或帧级别。

**理由（用户原话大意）**:

> 如果只是对乐句的几个节拍/音节的增量还是很难实现的，不管是基于拼接的模型还是扩散模型。比方说某次修改修改了第一句的某个字，又修改了后面某句副歌的混音参数，那么前面这个乐句会从头渲染，后面的会从混音开始。当然最后肯定是要对整首歌进行处理的，但那一般不会太耗时。

**设计含义**:

- 一个乐句是最小的"重算单元"
- 每个乐句内部有多个处理阶段（phoneme → acoustic features → waveform → mix）
- 脏标记可以精确到某乐句的某个阶段：改了歌词 → 从 phoneme 阶段开始重算；只改了混音参数 → 只重跑 mix 阶段
- 全曲级后处理（master EQ、响度归一化等）总是最后运行，通常不是瓶颈

### 3.2 流水线的阶段模型

```elixir
{:ok, recipes} = [
  {:add_node, %Node{id: :acoustic, impl: AcosticModel, inputs: [:lyrics], outputs: [:mel]}},
  {:add_node, %Node{id: :vocoder, impl: LegacyWaveNetVocoder,  inputs: [:mel], outputs: [:audio]}},
  {:add_edge, %Edge{from_node: :acoustic, from_port: :mel, to_node: :vocoder, to_port: :mel}},
  {:set_input, {:port, :acoustic, :lyrics}, phrase_i_lyrics}
]
|> Enum.reduce(%Quincunx.Session.Segment{}, &Quincunx.Session.Segment.apply_operation(&2, &1))
|> Quincunx.Session.Segment.compile_to_recipes()

# iex> recipes |> Enum.at(0)                           
# %{
#   exports: [],
#   requires: [:acoustic_lyrics],
#   overrides: %{},
#   inputs: %{{:port, :acoustic, :lyrics} => phrase_i_lyrics},
#   offsets: %{},
#   recipe: %Orchid.Recipe{
#     steps: [
#       {AcosticModel, [:acoustic_lyrics], [:acoustic_mel], []},
#       {LegacyWaveNetVocoder, [:acoustic_mel], [:vocoder_audio], []}
#     ],
#     name: [],
#     opts: []
#   },
#   node_ids: [:acoustic, :vocoder]
# }

#### What following are not implement yet. ####
recipes |> Quincunx.Session.Render.Task.run(cache_opts, pipeline_opts, ...)
```

每个阶段的输出可被缓存；脏标记决定从哪个阶段开始重算。

### 3.3 参数曲线系统

Quincunx 需要内建一个参数曲线子系统，用于对 pitch、dynamics、breathiness 等参数进行**时间域上的连续调制**。

**支持的曲线类型**:

- Linear interpolation
- Cubic Bézier
- （未来可能）Step / Hold、Catmull-Rom
- purely mannual edit(several points or other format)

曲线系统是**独立模块**，不依赖 Orchid 本身，但其输出会作为 `Orchid.Param` 流入流水线。

### 3.4 与 Orchid 的关系

Quincunx **不是** Orchid 的 fork 或替代品，而是 **建立在 Orchid 之上的领域应用层**。

**关键交互点**:

- Quincunx 根据脏区**动态构建 Orchid Recipe**（只包含需要重算的 Step）
- 缓存的中间产物作为 `Orchid.Param`（初始参数）注入 Recipe
- 曲线引擎的采样结果也封装为 `Orchid.Param`
- 推理后端通过 OrchidSymbiont 或自定义 Step 接入

### 4. 目前的源代码

#### Lily

```markdown
# 🌸Lily

**The pure functional DAG and compilation core.**

Lily handles the mathematical topology, user edit history, and execution plan generation for interactive editors. It delegates all side-effects and hardware scheduling to its host engine.

## 🎯 Philosophy

*   **Pure Data:** No GenServers, no ETS, zero side-effects.
*   **Time Travel:** O(1) Undo/Redo with zero memory copying.
*   **Deterministic:** Compiles user interventions and topological splits into strictly consistent `Orchid.Recipe`s.

## 🏗️ Architecture

1.  **`Lily.Graph`**: A strict, port-centric DAG. Connections and variables are defined by immutable keys (`{:port, node_id, port_name}`).
2.  **`Lily.History`**: A double-stack event sourcer. It folds chronological operations (node mutations, data overrides) into a single `effective_state`.
3.  **`Lily.Compiler`**: The translator. It partitions the graph into clusters (e.g., splitting heavy GPU nodes from CPU nodes), bridges cut edges via `requires/exports`, and maps user overrides into Orchid's execution baggage.

## 🚀 Quick Start

    alias Lily.{Graph, Graph.Node, Graph.Edge, Graph.Cluster, History, Compiler}

    # 1. Build the static topology
    graph = Graph.new()
    |> Graph.add_node(%Node{id: :acoustic, impl: AcosticModel, inputs: [:lyrics], outputs: [:mel]})
    |> Graph.add_node(%Node{id: :vocoder, impl: LegacyWaveNetVocoder,  inputs: [:mel], outputs: [:audio]})
    |> Graph.add_edge(Edge.new(:acoustic, :mel, :vocoder, :mel))

    # 2. Record user interventions (e.g., overriding AI tensors via UI)
    history = History.new()
    |> History.push({:override, {:port, :vocoder, :mel}, <<0, 1, "tensor_data">>})

    # 3. Fold history into the current effective state
    {graph, interventions} = History.resolve(graph, history)

    # 4. Compile & Partition (Split execution to prevent VRAM overflow)
    clusters = %Cluster{node_colors: %{acoustic: :gpu_1, vocoder: :gpu_2}}
    {:ok, recipes} = Compiler.compile(graph, clusters)
    [bundle_1, bundle_2] = Compiler.bind_interventions(recipes, interventions)

    # Result: 
    # bundle_1 exports :"acoustic_mel"
    # bundle_2 requires :"acoustic_mel" and carries the user override in its `overrides`.
```

```elixir
defmodule Lily.MixProject do
  use Mix.Project

  def project do
    [
      app: :lily,
      version: "0.1.0",
      elixir: "~> 1.19",
      start_permanent: Mix.env() == :prod,
      deps: deps()
    ]
  end

  # Run "mix help compile.app" to learn about applications.
  def application do
    [
      extra_applications: [:logger]
    ]
  end

  # Run "mix help deps" to learn about dependencies.
  defp deps do
    [
      {:orchid, "~> 0.5"}
    ]
  end
end


defmodule Lily do
  @moduledoc """
  Documentation for `Lily`.
  """

  @doc """
  Hello world.

  ## Examples

      iex> Lily.hello()
      :world

  """
  def hello do
    :world
  end
end

defmodule Lily.Compiler do
  @moduledoc """
  The final stage of the Lily pure functional pipeline.
  Translates the effective DAG into a sequence of Orchid.Recipe.
  """
  alias Lily.{Graph, History}
  alias Lily.Graph.{Node, Portkey, Cluster}

  @type recipe_manifest :: %{
          recipe: Orchid.Recipe.t(),
          requires: [Portkey.t()],
          exports: [Portkey.t()],
          node_ids: [Node.id()]
        }

  @type recipe_with_bundle :: %{
          recipe: Orchid.Recipe.t(),
          requires: [Portkey.t()],
          exports: [Portkey.t()],
          node_ids: [Node.id()],
          inputs: %{Portkey.t() => any()},
          overrides: %{Portkey.t() => any()},
          offsets: %{Portkey.t() => any()}
        }

  @spec compile(Graph.t()) :: {:error, :cycle_detected} | {:ok, [recipe_manifest()]}
  def compile(%Graph{} = graph, cluster_declara \\ %Cluster{}) do
    case Graph.topological_sort(graph) do
      {:error, _} = err ->
        err

      {:ok, sorted_node_ids} ->
        node_colors = Cluster.paint_graph(sorted_node_ids, graph.edges, cluster_declara)

        clusters = Enum.group_by(sorted_node_ids, &Map.get(node_colors, &1, :default_cluster))

        static_recipes =
          Enum.map(clusters, fn {cluster_name, node_ids_in_cluster} ->
            build_recipe(cluster_name, node_ids_in_cluster, graph)
          end)

        {:ok, static_recipes}
    end
  end

  @spec bind_interventions([recipe_manifest()], History.inputs_bundle()) :: [recipe_with_bundle()]
  def bind_interventions(static_recipes, %{inputs: inputs, overrides: overrides, offsets: offsets}) do
    Enum.map(static_recipes, fn %{node_ids: node_ids} = static_bundle ->
      local_inputs = filter_port_data(inputs, node_ids)
      local_overrides = filter_port_data(overrides, node_ids)
      local_offsets = filter_port_data(offsets, node_ids)

      static_bundle
      |> Map.put(:overrides, local_overrides)
      |> Map.put(:offsets, local_offsets)
      |> Map.put(:inputs, local_inputs)
    end)
  end

  defp build_recipe(cluster_name, node_ids, graph) do
    steps =
      node_ids
      |> Enum.map(&Map.fetch!(graph.nodes, &1))
      |> Enum.map(&node_to_step(&1, graph))

    {requires, exports} = calculate_boundaries(node_ids, graph)

    %{
      recipe: Orchid.Recipe.new(steps, name: cluster_name),
      requires: requires,
      exports: exports,
      node_ids: node_ids
    }
  end

  defp node_to_step(%Node{} = node, graph) do
    in_edges = Graph.get_in_edges(graph, node.id)

    step_inputs =
      Enum.map(node.inputs, fn port_name ->
        case Enum.find(in_edges, &(&1.to_port == port_name)) do
          nil -> Portkey.to_orchid_key({:port, node.id, port_name})
          edge -> Portkey.to_orchid_key({:port, edge.from_node, edge.from_port})
        end
      end)

    step_outputs = Enum.map(node.outputs, fn p -> Portkey.to_orchid_key({:port, node.id, p}) end)

    build_orchid_step(node.impl, step_inputs, step_outputs, node.opts)
  end

  defp calculate_boundaries(node_ids_in_cluster, graph) do
    cluster_nodes_set = MapSet.new(node_ids_in_cluster)

    external_in_edges =
      graph.edges
      |> Enum.filter(&(&1.to_node in cluster_nodes_set and &1.from_node not in cluster_nodes_set))
      |> Enum.map(&Portkey.to_orchid_key({:port, &1.from_node, &1.from_port}))

    dangling_inputs =
      Enum.flat_map(node_ids_in_cluster, fn node_id ->
        node = graph.nodes[node_id]
        in_edges = Graph.get_in_edges(graph, node_id)

        node.inputs
        |> Enum.reject(fn port -> Enum.any?(in_edges, &(&1.to_port == port)) end)
        |> Enum.map(fn port -> Portkey.to_orchid_key({:port, node.id, port}) end)
      end)

    requires = Enum.uniq(external_in_edges ++ dangling_inputs)

    exports =
      graph.edges
      |> Enum.filter(&(&1.from_node in cluster_nodes_set and &1.to_node not in cluster_nodes_set))
      |> Enum.map(&Portkey.to_orchid_key({:port, &1.from_node, &1.from_port}))
      |> Enum.uniq()

    {requires, exports}
  end

  defp filter_port_data(data_map, node_ids) do
    data_map
    |> Enum.filter(fn {{:port, target_node, _port}, _data} -> target_node in node_ids end)
    |> Enum.into(%{})
  end

  def build_orchid_step(impl, inputs, outputs, opts) do
    {impl, inputs, outputs, opts}
  end
end

defmodule Lily.Graph do
  @moduledoc """
  The pure mathematical representation of the DAG.
  """

  defmodule Node do
    @moduledoc "A pure data representation of a computation step in the DAG."

    @type id :: atom() | String.t()

    @type t :: %__MODULE__{
            id: id(),
            impl: Orchid.Step.implementation(),
            inputs: [atom()],
            outputs: [atom()],
            opts: keyword(),
            extra: map()
          }

    defstruct [
      :id,
      :impl,
      inputs: [],
      outputs: [],
      opts: [],
      extra: %{}
    ]
  end

  defmodule Edge do
    @moduledoc """
    A directed edge representing data flow between two node ports.

    It also serves as the deterministic variable name across the larger system.
    """

    @type t :: %__MODULE__{
            from_node: Node.id(),
            from_port: atom(),
            to_node: Node.id(),
            to_port: atom()
          }

    defstruct [:from_node, :from_port, :to_node, :to_port]

    def new(from_node, from_port, to_node, to_port) do
      %__MODULE__{
        from_node: from_node,
        from_port: from_port,
        to_node: to_node,
        to_port: to_port
      }
    end
  end

  defmodule Portkey do
    @type t :: {:port, node :: Node.id(), port :: atom()}

    @spec to_orchid_key(t()) :: atom()
    def to_orchid_key({:port, node, port}) do
      :"#{node}_#{port}"
    end
  end

  @type t :: %__MODULE__{
          nodes: %{Node.id() => Node.t()} | %{},
          edges: MapSet.t(Edge.t()) | MapSet.t()
        }

  defstruct nodes: %{}, edges: MapSet.new()

  def new, do: %__MODULE__{}

  # https://elixirforum.com/t/what-is-a-good-way-to-compare-structs/59303
  @spec same?(t(), t()) :: boolean()
  def same?(graph1, graph2), do: graph1 == graph2

  @spec add_node(t(), Node.t()) :: t()
  def add_node(%__MODULE__{nodes: old_nodes} = graph, %Node{id: node_id} = node) do
    %{graph | nodes: Map.put(old_nodes, node_id, node)}
  end

  @spec remove_node(t(), Node.id()) :: t()
  def remove_node(%__MODULE__{nodes: nodes, edges: edges}, node_id) do
    case nodes[node_id] do
      nil ->
        %__MODULE__{nodes: nodes, edges: edges}

      _ ->
        %__MODULE__{
          nodes: Map.delete(nodes, node_id),
          edges:
            edges
            |> Enum.reject(&(&1.from_node == node_id or &1.to_node == node_id))
            |> Enum.into(%MapSet{})
        }
    end
  end

  @spec update_node(t(), Node.id(), new_node :: Node.t()) :: t()
  def update_node(%__MODULE__{nodes: nodes} = graph, node_id, new_node) do
    case nodes[node_id] do
      nil ->
        graph

      old_node = %Node{} ->
        %{
          graph
          | nodes: %{
              nodes
              | node_id =>
                  case new_node do
                    new_node when is_function(new_node, 1) -> new_node.(old_node)
                    _ -> new_node
                  end
            }
        }
    end
  end

  @spec add_edge(t(), Edge.t()) :: t()
  def add_edge(%__MODULE__{} = graph, edge) do
    %{graph | edges: MapSet.put(graph.edges, edge)}
  end

  @spec remove_edge(t(), Edge.t()) :: t()
  def remove_edge(%__MODULE__{edges: edges} = graph, edge) do
    %{
      graph
      | edges:
          edges
          |> Enum.reject(&(&1 == edge))
          |> Enum.into(%MapSet{})
    }
  end

  @doc "获取指向某节点的所有输入边"
  @spec get_in_edges(t(), Node.t()) :: [Edge.t()]
  def get_in_edges(%__MODULE__{} = graph, node_id) do
    Enum.filter(graph.edges, &(&1.to_node == node_id))
  end

  @doc "获取从某节点发出的所有输出边"
  @spec get_out_edges(t(), Node.t()) :: [Edge.t()]
  def get_out_edges(%__MODULE__{} = graph, node_id) do
    Enum.filter(graph.edges, &(&1.from_node == node_id))
  end

  @spec topological_sort(t()) :: {:ok, [Node.id()]} | {:error, :cycle_detected}
  def topological_sort(%__MODULE__{} = graph) do
    # 1. 初始化所有节点的入度 (In-degree) 为 0
    init_in_degrees = Map.keys(graph.nodes) |> Map.new(fn id -> {id, 0} end) |> Enum.into(%{})

    # 2. 遍历所有边，计算每个节点的真实入度
    in_degrees =
      Enum.reduce(graph.edges, init_in_degrees, fn edge, acc ->
        Map.update!(acc, edge.to_node, &(&1 + 1))
      end)

    # 3. 找出所有入度为 0 的游离节点（图的起始触发点）
    zero_in_degree_nodes =
      in_degrees
      |> Enum.filter(fn {_id, degree} -> degree == 0 end)
      |> Enum.map(fn {id, _degree} -> id end)

    # 4. 开始递归剥离图
    do_topo_sort(zero_in_degree_nodes, in_degrees, graph, [])
  end

  # Kahn 算法的核心递归
  defp do_topo_sort([], _in_degrees, graph, sorted_acc) do
    # 如果已排序的节点数量等于图中的总节点数，说明排序成功
    if length(sorted_acc) == map_size(graph.nodes) do
      {:ok, Enum.reverse(sorted_acc)}
    else
      # 还有节点没被剥离，说明它们互相依赖，形成了死锁（环）！
      {:error, :cycle_detected}
    end
  end

  defp do_topo_sort([node_id | rest_zero_nodes], in_degrees, graph, sorted_acc) do
    # 遍历入度为 0 的边，将它们指向的下游节点的入度减 1
    {new_in_degrees, new_zero_nodes} =
      graph.edges
      |> Enum.filter(&(&1.from_node == node_id))
      |> Enum.reduce({in_degrees, rest_zero_nodes}, fn edge, {deg_acc, zero_acc} ->
        new_deg = deg_acc[edge.to_node] - 1
        deg_acc = Map.put(deg_acc, edge.to_node, new_deg)

        # 如果下游节点的入度变成了 0，将其加入下一轮待处理队列
        case new_deg do
          0 -> {deg_acc, [edge.to_node | zero_acc]}
          _ -> {deg_acc, zero_acc}
        end
      end)

    # 递归处理下一批入度为 0 的节点
    do_topo_sort(new_zero_nodes, new_in_degrees, graph, [node_id | sorted_acc])
  end
end

defmodule Lily.Graph.Cluster do
  # 将依赖依照用户选择以及依赖关系分簇
  # 以实现并行控制
  # 人话：将部分很耗费资源的服务单独丢出去
  # 将整个并行改成串行 + 并行
  alias Lily.Graph.{Node, Edge}

  @type cluster_name :: atom() | String.t() | [cluster_name()]

  @type t :: %__MODULE__{
          node_colors: %{Node.id() => cluster_name()},
          merge_groups: [{cluster_name() | MapSet.t(cluster_name()), cluster_name()}]
        }
  defstruct node_colors: %{},
            merge_groups: []

  @spec paint_graph([Node.t()], MapSet.t(Edge.t()), Lily.Graph.Cluster.t()) ::
          %{Node.id() => cluster_name()}
  @doc "Return `%{node_name => final_cluster_name}`"
  def paint_graph(sorted_nodes, edges, %__MODULE__{} = clusters) do
    Enum.reduce(sorted_nodes, %{}, fn node_id, color_map ->
      cond do
        explicit_color = Map.get(clusters.node_colors, node_id) ->
          Map.put(color_map, node_id, explicit_color)

        true ->
          Map.put(color_map, node_id, get_upstream_colors(node_id, edges, color_map))
      end
    end)
    # normalize clusters
    |> Enum.map(fn {k, v} -> {k, case v do v when is_list(v) -> Enum.sort(v); v -> v end} end)
    |> Enum.into(%{})
  end

  defp get_upstream_colors(node_id, edges, color_map) do
    Enum.filter(edges, fn e -> e.to_node == node_id end)
    |> case do
      [] -> []
      _ = upper_edges -> Enum.map(upper_edges, fn e -> e.from_node end)
    end
    |> Enum.map(&Map.get(color_map, &1, :default_cluster))
    # [[:foo, :bar], :bar] => [:foo, :bar]
    |> List.flatten()
    |> Enum.uniq()
  end
end

defmodule Lily.History do
  defmodule Operation do
    alias Lily.Graph.{Node, Edge, Portkey}

    @type topology_mutation ::
            {:add_node, Node.t()}
            | {:update_node, Node.id(),
               node_or_update_funtion :: Node.t() | (Node.t() -> Node.t())}
            | {:remove_node, Node.id()}
            | {:add_edge, Edge.t()}
            | {:remove_edge, Edge.t()}

    @type input_declar ::
            {:set_input, Portkey.t(), data :: any()}
            | {:remove_input, Portkey.t()}

    @type data_interventions ::
            {:override, Portkey.t(), data :: any()}
            | {:offset, Portkey.t(), data :: any()}
            | {:remove_interventions, Portkey.t()}

    @type t :: topology_mutation() | data_interventions() | input_declar()
  end

  alias Lily.Graph

  @type inputs_bundle :: %{
          :inputs => %{Lily.Graph.Portkey.t() => any()},
          :overrides => %{Lily.Graph.Portkey.t() => any()},
          :offsets => %{Lily.Graph.Portkey.t() => any()},
          optional(any()) => any()
        }

  @type effective_state :: {Lily.Graph.t(), inputs_bundle()}

  @type t :: %__MODULE__{
          # 越新的操作越靠前 (Head)
          undo_stack: [Operation.t()],
          # 越靠近当前时间点的“未来”越靠前
          redo_stack: [Operation.t()]
        }

  defstruct undo_stack: [], redo_stack: []

  @doc "初始化一个新的历史记录"
  def new, do: %__MODULE__{}

  @spec push(t(), any()) :: t()
  def push(%__MODULE__{undo_stack: undo} = history, op) do
    %{history | undo_stack: [op | undo], redo_stack: []}
  end

  @spec undo(t()) :: t()
  def undo(%__MODULE__{undo_stack: []} = history), do: history

  def undo(%__MODULE__{undo_stack: [last_op | rest_undo], redo_stack: redo} = history) do
    %{history | undo_stack: rest_undo, redo_stack: [last_op | redo]}
  end

  @spec redo(t()) :: t()
  def redo(%__MODULE__{redo_stack: []} = history), do: history

  def redo(%__MODULE__{undo_stack: undo, redo_stack: [next_op | rest_redo]} = history) do
    %{history | undo_stack: [next_op | undo], redo_stack: rest_redo}
  end

  @doc """
  将所有的历史记录（过去）按时间顺序叠加到 base_graph 上。
  输出 Compiler 和 Orchid 真正需要的有效状态。
  """
  @spec resolve(Graph.t(), t()) :: effective_state()
  def resolve(%Graph{} = base_graph, %__MODULE__{undo_stack: undo_stack}) do
    initial_state = %{graph: base_graph, inputs: %{}, overrides: %{}, offsets: %{}}

    undo_stack
    |> Enum.reverse()
    |> Enum.reduce(initial_state, &apply_operation/2)
    |> Map.pop(:graph)
  end

  defp apply_operation({:add_node, node}, state) do
    %{state | graph: Graph.add_node(state.graph, node)}
  end

  defp apply_operation({:update_node, node_id, new_node}, state) do
    %{state | graph: Graph.update_node(state.graph, node_id, new_node)}
  end

  defp apply_operation({:remove_node, node_id}, state) do
    %{state | graph: Graph.remove_node(state.graph, node_id)}
  end

  defp apply_operation({:add_edge, edge}, state) do
    %{state | graph: Graph.add_edge(state.graph, edge)}
  end

  defp apply_operation({:remove_edge, edge}, state) do
    %{state | graph: Graph.remove_edge(state.graph, edge)}
  end

  defp apply_operation({:override, {:port, _, _} = port_key, value}, state) do
    %{state | overrides: Map.put(state.overrides, port_key, value)}
  end

  defp apply_operation({:offset, {:port, _, _} = port_key, value}, state) do
    %{state | offsets: Map.put(state.offsets, port_key, value)}
  end

  defp apply_operation({:remove_interventions, {:port, _, _} = port_key}, state) do
    %{
      state
      | overrides: Map.delete(state.overrides, port_key),
        offsets: Map.delete(state.offsets, port_key)
    }
  end

  defp apply_operation({:set_input, port_key, data}, state) do
    %{state | inputs: Map.put(state.inputs, port_key, data)}
  end

  defp apply_operation({:remove_input, port_key}, state) do
    %{state | inputs: Map.delete(state.inputs, port_key)}
  end
end
```

#### Quincunx

```elixir
defmodule Quincunx.Session.Segment do
  @moduledoc """
  The smallest unit for incremental generation.
  It holds the static topology, user edit history, and cached runtime references.
  """

  alias Lily.History.Operation
  alias Lily.{Graph, History, Compiler, Graph.Cluster}

  @type id :: atom() | String.t()

  @type t :: %__MODULE__{
          id: id(),
          graph_with_cluster: {Graph.t(), Cluster.t()},
          compiled_recipes: nil | [Compiler.recipe_with_bundle()],
          history: History.t(),
          snapshots: %{optional(atom()) => any()},
          extra: map()
        }

  defstruct [
    :id,
    graph_with_cluster: {%Graph{}, %Cluster{}},
    compiled_recipes: nil,
    history: %History{},
    snapshots: %{},
    extra: %{}
  ]

  @spec new(id(), Graph.t()) :: t()
  @spec new(id(), Graph.t(), Cluster.t()) :: t()
  def new(id, graph, cluster_declara \\ %Cluster{}) do
    %__MODULE__{
      id: id,
      graph_with_cluster: {graph, cluster_declara},
      history: History.new()
    }
  end

  @spec apply_operation(t(), Operation.t()) :: t()
  def apply_operation(%__MODULE__{} = segment, operation) do
    %{segment | history: History.push(segment.history, operation)}
  end

  @spec undo(t()) :: t()
  def undo(%__MODULE__{} = segment) do
    %{segment | history: History.undo(segment.history)}
  end

  @spec redo(t()) :: t()
  def redo(%__MODULE__{} = segment) do
    %{segment | history: History.redo(segment.history)}
  end

  @spec compile_to_recipes([t()] | t()) ::
          {:ok, Compiler.recipe_with_bundle() | [t()]} | {:error, term()}
  def compile_to_recipes(%__MODULE__{} = segment) do
    case compile_to_recipes([segment]) do
      {:ok, [compiled_seg]} -> {:ok, compiled_seg.compiled_recipes}
      {:error, _} = err -> err
    end
  end

  def compile_to_recipes(segments) when is_list(segments) do
    segments
    |> Enum.map(fn seg ->
      {base_graph, cluster} = seg.graph_with_cluster
      {final_graph, interventions} = History.resolve(base_graph, seg.history)

      %{
        segment: seg,
        group_key: {final_graph, cluster},
        interventions: interventions
      }
    end)
    |> Enum.group_by(& &1.group_key)
    # %{{graph, cluster}, [%{segment: seg, interventions: interventions}]}
    |> Enum.reduce_while({:ok, []}, fn {{graph, cluster}, items}, {:ok, acc} ->
      case Compiler.compile(graph, cluster) do
        {:ok, static_recipes} ->
          compiled_group =
            Enum.map(items, fn item ->
              bound_recipes =
                static_recipes
                |> List.wrap()
                |> Compiler.bind_interventions(item.interventions)

              %{item.segment | compiled_recipes: bound_recipes}
            end)

          {:cont, {:ok, acc ++ compiled_group}}

        {:error, reason} ->
          {:halt, {:error, reason}}
      end
    end)
  end
end
```

---

# 本次 Session 目标

设计并实现 `Quincunx.RenderEngine`。

1. 它需要接收 `Lily` 吐出的 `[Recipe]` 序列和 100 个需要被并发渲染的 `Segments`（乐句）。
2. 使用 `Task.async_stream` 实现**阶段式屏障批处理（Stage-Sequential Batching）**。
3. 设计并落地 **黑板机制 (Blackboard)**：一个生命周期仅限于单次渲染的键值对字典。它负责收集上一个 Recipe 阶段产出的 `Orchid.Param`，并在下一个 Recipe 阶段被唤醒时，根据 `requires` 准确地把参数喂给执行器。不涉及具体的业务计算，纯粹做数据引用的搬运工。

请从 Elixir OTP 和数据流的角度，为我搭建这个 Engine 的核心流转代码。

*以下「其他上下文」所涉及到的缓存机制不是本 Session 的主要目的，因其复杂性过高不用在本 Session 中过于深入。*

## 其他上下文：数据本体保存 vs 跨 Recipe 生命周期的保存

> 可否再说一下黑板和缓存的关系呢？我们对于缓存的 impl 好像一直都没有落地。

这是一个绝对关键的灵魂拷问！理清这两者的关系，整个系统的任督二脉才算彻底打通。

为了让你一目了然，我们可以用一个工厂的隐喻来界定它们的边界，然后再把缺失的 **「Cache 落地实现」** 补齐。

### 1. 概念解耦：黑板（传送带） vs 缓存（仓库）

*   **黑板 (Blackboard)** = **跨配方数据传送带（瞬时状态）**
    *   **生命周期**：极短。从按下了“播放键”开始，到 100 个乐句跑完发出声音结束，黑板就被销毁了。
    *   **形态**：映射关系是 `PortKey -> Param`（例如 `{:port, :acoustic, :mel} -> %Param{}`）。
    *   **职责**：因为 Lily 把大图切成了 `Cluster_CPU` 和 `Cluster_GPU`，黑板的唯一作用就是让 `GPU` 启动时，能拿到 `CPU` 刚才算出来的输出参数。**黑板不在乎数据是怎么来的**（不管是硬算的，还是从缓存里捞的，黑板只负责当快递员）。
*   **缓存 (Cache)** = **增量计算的记忆仓库（持久状态）**
    *   **生命周期**：极长。甚至跨越软件的多次启动（存盘在 DETS/文件系统里）。
    *   **形态**：映射关系是 `Computation_Signature (Hash) -> Param`。
    *   **职责**：决定“算”还是“跳过”。拦截重型步骤，通过指纹比对，如果一模一样，直接变出结果扔给黑板，从而保护 CPU/GPU 资源。

---

### 2. 缓存 (Cache) 的真正落地实现

要让缓存跑起来，我们需要两部分：**哈希签名生成器** 和 **拦截钩子 (CacheHook)**。

#### A. 核心难点：怎么算 Hash？
计算 Hash 最忌讳的就是“把几个 G 的张量数据取出来去算 Hash”。我们在前面的讨论中确立过：`Param` 的 `payload` 里往往存放的是引用（`{:ref, repo, key}`）。
此外，我们刚才在 `DataInterventionHook` 里把 offset 写进了 `metadata._orchid_offset`，**这个 Offset 必须参与 Hash 计算**，否则用户拉动了变调滑块，系统还会返回旧的音频！

```elixir
defmodule Quincunx.Cache.Signature do
  @moduledoc "为单次计算生成确定性的指纹 (Hash)"

  def generate_hash(impl, inputs, opts) do
    # 1. 提取所有输入的“特征指纹”
    inputs_fingerprints = Enum.map(inputs, &extract_param_fingerprint/1)
    
    # 2. 清理 opts 中不稳定的部分（比如 telemetry_meta 或运行时 PID）
    stable_opts = Keyword.drop(opts, [:__reporter_ctx__, :baggage, :hooks])

    # 3. 组合成 Erlang Term
    term_to_hash = {impl, inputs_fingerprints, stable_opts}
    
    # 4. 生成极速的 256 位 Hash
    :crypto.hash(:sha256, :erlang.term_to_binary(term_to_hash))
    |> Base.encode16(case: :lower)
  end

  # =--- 多态提取 Param 特征 ---=
  
  # 情况 A：数据如果是个胖引用（NIF 句柄 / 文件路径），我们只 Hash 它的引用 Key！极速！
  defp extract_param_fingerprint(%Orchid.Param{payload: {:ref, _repo, ref_key}} = param) do
    {ref_key, Map.get(param.metadata, :_orchid_offset)}
  end
  
  # 情况 B：数据如果是轻量的原子、数字或短文本，直接 Hash 它的裸值
  defp extract_param_fingerprint(%Orchid.Param{payload: raw_data} = param) 
       when is_binary(raw_data) or is_number(raw_data) or is_atom(raw_data) do
    {raw_data, Map.get(param.metadata, :_orchid_offset)}
  end

  # 情况 C：其他容错（比如嵌套结构），用 Erlang 自带的哈希
  defp extract_param_fingerprint(other) do
    :erlang.phash2(other)
  end
end
```

#### B. CacheHook (缓存短路拦截器)

在 `Orchid.Runner` 的洋葱模型里，**如果 Hook 不调用 `next.(ctx)`，它就会直接打断管线**并原路返回。这正是完美实现缓存短路的地方！

```elixir
defmodule Quincunx.Hooks.Cache do
  @behaviour Orchid.Runner.Hook
  alias Quincunx.Cache.Signature
  alias Quincunx.GlobalCacheRepo # 假设这是你的 ETS/DETS 存储进程

  require Logger

  @spec call(Orchid.Runner.Context.t(), Orchid.Runner.Hook.next_fn()) ::
          Orchid.Runner.Hook.hook_result()
  def call(ctx, next) do
    # 1. 计算当前步骤的纯粹计算签名
    step_hash = Signature.generate_hash(ctx.step_implementation, ctx.inputs, ctx.step_opts)

    # 2. 查仓库
    case GlobalCacheRepo.get(step_hash) do
      {:ok, cached_output_params} ->
        Logger.debug("Cache HIT! 命中缓存短路: #{ctx.step_implementation}")
        # 【核心技巧】：不调用 next.(ctx)，直接返回成功的 tuple！
        # 这会让底层的 Hooks.Core（真正调 NIF/跑模型的地方）被彻底跳过！
        # 但外层的 Telemetry 依然会收到 {:ok, result}，可观测性完美保留。
        {:ok, cached_output_params}

      :error ->
        Logger.debug("Cache MISS: #{ctx.step_implementation}，执行深度计算...")
        
        # 没命中，必须硬算。调用 next.(ctx) 走向 CoreHook
        case next.(ctx) do
          {:ok, outputs} ->
            # 计算成功后，把结果写回仓库，留给下次用
            GlobalCacheRepo.put(step_hash, outputs)
            {:ok, outputs}
            
          other_result ->
            # 如果底层计算报错了，直接透传，千万别缓存错误结果
            other_result
        end
    end
  end
end
```

### 3. 把它们串起来的宏观图景

让我们回放一下 `Segment` 第 99 乐句在 Engine 里的奇妙旅程：

1.  **用户推了一下变调滑块**。
2.  `Lily` 瞬间折叠历史，吐出了带有 `offsets: %{{:port, :vocoder, :mel} => +2.0}` 的配方。
3.  `BatchOrchestrator` 把 100 个乐句扔进流水线。
4.  **【黑板运作】**：到了 Vocoder (声码器) 节点，黑板把上一步声学模型生成的 `Param (payload: {:ref, repo, "mel_tensor_abc"})` 拔出来，交给了 Orchid。
5.  **【DataInterventionHook】**：拦截，发现 `baggage` 里有 `+2.0`。它不会去改张量，而是把 `metadata: %{_orchid_offset: 2.0}` 塞进了这个 `Param` 里。
6.  **【CacheHook】**：开始算 Hash。
    *   乐句 1 到 98，`offset` 还是缺省的 `nil`。`Signature.generate_hash` 算出来的指纹在仓库里找得到。**Hit！跳过 GPU 渲染，瞬间返回音频。**
    *   乐句 99，因为 `offset` 变成了 `2.0`，计算出的 `step_hash` 变了！在仓库里找不到。**Miss！** 放行到 `Hooks.Core` 开始硬算这一个乐句的 GPU 渲染。算完后，把变调后的音频写回仓库。
7.  **【黑板运作】**：Orchid 返回了新算好的音频 Param，黑板又把它装载上去，最终存进工程。
